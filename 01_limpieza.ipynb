{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8805710e",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos PAC\n",
    "\n",
    "Limpieza y preparación de datos para model de detección de anomalías.\n",
    "Utiliza datos de los Beneficiarios de Ayuda de la Política Agrícola Común de 2024.\n",
    "\n",
    "https://www.fega.gob.es/es/datos-abiertos/consulta-de-beneficiarios-pac/descarga-de-ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f02d33",
   "metadata": {},
   "source": [
    "## Preparar ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30613731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lizziecanamar/Documents/MASTER/TFM/Implementations/ml-spark-use-case/.venv/lib/python3.11/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F, types as T\n",
    "import pyspark.pandas as ps\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9040f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/10 11:29:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/09/10 11:29:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Iniciar Spark session\n",
    "spark = SparkSession.builder.appName(\"PAC_Preprocesado\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea672488",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/Beneficiarios_municipio_ejercicio_financiero_2024.txt\"\n",
    "output_path = \"data/pac_2024_clean/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25e3ca",
   "metadata": {},
   "source": [
    "## Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54d6c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------+-------------+--------------------+------------+-------+-------+--------+------+------------+------------+-------------+\n",
      "|        BENEFICIARIO|GRUPO_EMPRESA|PROVINCIA|    MUNICIPIO|              MEDIDA|OBJETIVO_ESP|FEC_INI|FEC_FIN|   FEAGA|FEADER|IMPORTECOFIN|FEADER_COFIN|IMPORTE_EUROS|\n",
      "+--------------------+-------------+---------+-------------+--------------------+------------+-------+-------+--------+------+------------+------------+-------------+\n",
      "|: HERENCIA YACENT...|         null|   Madrid|28982 - Parla|II.1   Régimen de...|        null|   null|   null|24217,98|     0|           0|           0|     24217,98|\n",
      "|: HERENCIA YACENT...|         null|   Madrid|28982 - Parla|II.4   Pago para ...|        null|   null|   null|12650,71|     0|           0|           0|     12650,71|\n",
      "|: HERENCIA YACENT...|         null|   Madrid|28982 - Parla|I.6   Ayuda a la ...|     OE2|OE6|   null|   null|16969,68|     0|           0|           0|     16969,68|\n",
      "|: HERENCIA YACENT...|         null|   Madrid|28982 - Parla|I.4   Regímenes e...| OE4|OE5|OE6|   null|   null|10467,01|     0|           0|           0|     10467,01|\n",
      "|: HERENCIA YACENT...|         null|   Madrid|28982 - Parla|II.7   Ayuda asoc...|        null|   null|   null|16174,39|     0|           0|           0|     16174,39|\n",
      "+--------------------+-------------+---------+-------------+--------------------+------------+-------+-------+--------+------+------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Leer datos\n",
    "df_raw = spark.read.csv(input_path,sep=\";\", header=True, encoding=\"latin1\", inferSchema=False)\n",
    "df_raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8317ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes de quitar duplicados:  2217849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:======>                                                    (1 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de quitar duplicados:  2217834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Duplicados\n",
    "print(\"Antes de quitar duplicados: \",df_raw.count())\n",
    "df = df_raw.dropDuplicates()\n",
    "print(\"Después de quitar duplicados: \",df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0d3706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+---------+---------+------+--------------------+------------------+------------------+---------------------+------+------------+------------+-------------+\n",
      "|BENEFICIARIO|GRUPO_EMPRESA    |PROVINCIA|MUNICIPIO|MEDIDA|OBJETIVO_ESP        |FEC_INI           |FEC_FIN           |FEAGA                |FEADER|IMPORTECOFIN|FEADER_COFIN|IMPORTE_EUROS|\n",
      "+------------+-----------------+---------+---------+------+--------------------+------------------+------------------+---------------------+------+------------+------------+-------------+\n",
      "|0.0         |0.998159465496516|0.0      |0.0      |0.0   |0.057901989057792425|0.9971219667477368|0.9981630726195018|4.5089037321999755E-7|0.0   |0.0         |0.0         |0.0          |\n",
      "+------------+-----------------+---------+---------+------+--------------------+------------------+------------------+---------------------+------+------------+------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Porcentaje de nulos (para análisis)\n",
    "nulls = df.select([ (F.count(F.when(F.col(c).isNull(), c)) / F.count(\"*\")).alias(c) for c in df.columns ])\n",
    "nulls.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b588c410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/10 11:30:14 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 19:=========================>                                (4 + 5) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|Column       |Value             |\n",
      "+-------------+------------------+\n",
      "|GRUPO_EMPRESA|0.998159465496516 |\n",
      "|FEC_INI      |0.9971219667477368|\n",
      "|FEC_FIN      |0.9981630726195018|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Mostrar columnas donde los nulos > 65%\n",
    "columns = [col for col in nulls.columns if col != \"summary\"]\n",
    "\n",
    "unpivoted_df = nulls.selectExpr(\"stack(\" + str(len(columns)) + \", \" +\n",
    "                             \", \".join([f\"'{col}', `{col}`\" for col in columns]) +\n",
    "                             \") as (Column, Value)\")\n",
    "\n",
    "filtered_df = unpivoted_df.filter(F.col(\"Value\") > 0.65)\n",
    "filtered_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba35d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluir columnas con >65% nulos\n",
    "df_clean = df.drop(\"GRUPO_EMPRESA\", \"FEC_INI\", \"FEC_FIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe0cb4",
   "metadata": {},
   "source": [
    "### Ajuste de esquema/tipos de dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59575bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir decimales con coma a punto\n",
    "num_cols = [\"FEAGA\",\"FEADER\",\"IMPORTECOFIN\",\"FEADER_COFIN\",\"IMPORTE_EUROS\"]\n",
    "\n",
    "for c in num_cols:\n",
    "    df_clean = df_clean.withColumn(c, F.regexp_replace(c, \",\", \".\").cast(T.DoubleType()))\n",
    "\n",
    "df_clean = ( df_clean\n",
    "            # Beneficiario: quitar prefijo \": \" y trim\n",
    "            .withColumn(\"BENEFICIARIO\", F.trim(F.regexp_replace(\"BENEFICIARIO\", \"^: ?\", \"\")))\n",
    "            # Separar código y nombre de los municipios\n",
    "            .withColumn(\"MUNICIPIO_COD\", F.trim(F.split(\"MUNICIPIO\", \"-\").getItem(0)))\n",
    "            .withColumn(\"MUNICIPIO_NOMBRE\", F.trim(F.split(\"MUNICIPIO\", \"-\").getItem(1)))\n",
    "            # Convertir nulos en string vacío\n",
    "            .withColumn(\"OBJETIVO_ESP\", F.coalesce(F.col(\"OBJETIVO_ESP\"), F.lit(\"\")))\n",
    "            ).drop(\"MUNICIPIO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc6741",
   "metadata": {},
   "source": [
    "### Agregar flag de recuperaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7edea608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag  por importe negativo o MEDIDA que contenga 'Recuperaciones'\n",
    "df_clean = (df_clean\n",
    "           .withColumn(\"IS_RECUP\", (F.col(\"IMPORTE_EUROS\") < 0).cast(\"int\"))\n",
    "           .withColumn(\"IS_RECUP_MEDIDA\", F.locate(\"Recuperaciones\", F.col(\"MEDIDA\")).cast(\"int\"))\n",
    "           .withColumn(\"IS_RECUP_ANY\", ((F.col(\"IS_RECUP\") == 1) | (F.col(\"IS_RECUP_MEDIDA\") > 0)).cast(\"int\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70e874",
   "metadata": {},
   "source": [
    "### Limpieza nombres de provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01080a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilingual_map = {\n",
    "    \"València/Valencia\": \"Valencia\",\n",
    "    \"Alacant/Alicante\": \"Alicante\",\n",
    "    \"Castelló/Castellón\": \"Castellon\",  \n",
    "}\n",
    "\n",
    "# UDF para normalizar a ASCII (quitar acentos)\n",
    "def strip_accents(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = s.strip()\n",
    "    s = bilingual_map.get(s, s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = \" \".join(s.split())\n",
    "    s = s.replace(\" \", \"-\")\n",
    "    return s\n",
    "\n",
    "strip_accents_udf = F.udf(strip_accents, T.StringType())\n",
    "\n",
    "df_out = df_clean.withColumn(\"PROVINCIA_SAFE\", strip_accents_udf(F.col(\"PROVINCIA\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75b98f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar distribución tras normalizar\n",
    "#df_out.groupBy(\"PROVINCIA\", \"PROVINCIA_SAFE\").count().orderBy(F.desc(\"count\")).show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8532106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes de quitar duplicados:  2217834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:===================>                                      (3 + 6) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de quitar duplicados:  2217817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Duplicados\n",
    "print(\"Antes de quitar duplicados: \",df_clean.count())\n",
    "df_out = df_out.dropDuplicates()\n",
    "print(\"Después de quitar duplicados: \",df_out.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359c274",
   "metadata": {},
   "source": [
    "## Guardar parquet limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492b1927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/10 11:31:43 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/09/10 11:31:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/09/10 11:31:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/09/10 11:31:45 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/09/10 11:31:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/09/10 11:31:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/09/10 11:31:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/09/10 11:31:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/09/10 11:31:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df_out\n",
    "    .write.mode(\"overwrite\")\n",
    "    .partitionBy(\"PROVINCIA_SAFE\")\n",
    "    .option(\"compression\", \"snappy\")\n",
    "    .parquet(output_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592a9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the cache in Spark\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-spark-use-case (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
